{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from config import *\n",
    "\n",
    "import numpy as np \n",
    "import math \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = Connector(**BIGQUERY_CONFIG)\n",
    "\n",
    "\n",
    "istanbul_inputs = {\n",
    "    \"shape_query\" : QueryArgs(\n",
    "        filename = \"area-shapes.sql\",\n",
    "        params = {\n",
    "            \"country_code\":\"tr\",\n",
    "            \"city\":\"Istanbul\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    , \"session_query\" : QueryArgs(\n",
    "        filename = \"sessions-with-area.sql\",\n",
    "        params = {\n",
    "            \"country_code\":\"tr\",\n",
    "            \"city\":\"Istanbul\",\n",
    "            \"entity_id\":\"YS_TR\",\n",
    "            \"weeks_ago\":3,\n",
    "            \"city_id\":1,\n",
    "            \"asa_ids\":[334]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    , \"city_query\" : QueryArgs(\n",
    "        filename = \"city-dh-shape.sql\",\n",
    "        params = {\n",
    "            \"entity_id\":\"YS_TR\",\n",
    "            \"city_id\":1\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID 0d138cd8-3043-4f14-b7ce-6c56145293e1 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Job ID 01a2ab2c-bf88-4207-82e0-ba6a9ecb305b successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Job ID 5185dbfa-7009-490a-97c5-1de6579360c6 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n"
     ]
    }
   ],
   "source": [
    "session_data = connector.get_df_from_query(QueryHandler.build_query(istanbul_inputs[\"session_query\"]))\n",
    "\n",
    "area_shapes = (\n",
    "    connector\n",
    "    .get_df_from_query(QueryHandler.build_query(istanbul_inputs[\"shape_query\"]))\n",
    "    .pipe(convert_to_geopandas, \"area_shape\")\n",
    "    .drop(columns=[\"area_shape\"])\n",
    ")\n",
    "\n",
    "city_dh_shape = (\n",
    "    connector\n",
    "    .get_df_from_query(QueryHandler.build_query(istanbul_inputs[\"city_query\"]))\n",
    "    .pipe(convert_to_geopandas, \"city_shape\")\n",
    "    .drop(columns=[\"city_shape\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>n_conversions</th>\n",
       "      <th>perseus_client_id</th>\n",
       "      <th>cvr_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_sessions</th>\n",
       "      <td>968047.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_conversions</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39989.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_users</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198673.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cvr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   n_sessions  n_conversions  perseus_client_id  cvr_user\n",
       "total_sessions       968047.0            NaN                NaN       NaN\n",
       "total_conversions         NaN        39989.0                NaN       NaN\n",
       "n_users                   NaN            NaN           198673.0       NaN\n",
       "avg_cvr                   NaN            NaN                NaN  0.041348"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_data.groupby(\"area_name\").size().sort_values(ascending=False)\n",
    "filter_area = \"Kadıköy\"\n",
    "test_area = session_data.query(f\"area_name=='{filter_area}'\")\n",
    "\n",
    "(\n",
    "    test_area \n",
    "    .assign(\n",
    "        cvr_user = lambda df: df.n_conversions.div(df.n_sessions)\n",
    "    )\n",
    "    .agg(\n",
    "        total_sessions = (\"n_sessions\", \"sum\"),\n",
    "        total_conversions = (\"n_conversions\", \"sum\"),\n",
    "        n_users = (\"perseus_client_id\", \"count\"),\n",
    "        avg_cvr = (\"cvr_user\", \"mean\")\n",
    "    )\n",
    "    # .melt()\n",
    "    # .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class DeltaParameters:\n",
    "    \"\"\"Holds the parameters relevant to delta method variance.\n",
    "    more info here: https://arxiv.org/abs/2305.16459\n",
    "\n",
    "    As a general definition\n",
    "    denom_mean -> Denominator mean, \n",
    "    demon_var -> Denominator Variance\n",
    "    num_mean -> numerator mean\n",
    "    num_var -> numerator variance\n",
    "    covar -> covariance between numerator and denominator\n",
    "\n",
    "    For example, sessions per user acts a denominator while transactions per user does it as numerator.\n",
    "    \"\"\"\n",
    "    denom_mean:float\n",
    "    num_mean:float \n",
    "    denom_var:float \n",
    "    num_var:float \n",
    "    covar:float \n",
    "    cvr:float \n",
    "    sample_size:float\n",
    "    \n",
    "    def calculate_variance_factor(self):\n",
    "        \"\"\" h is the variable name in the paper source. \n",
    "        I view is as an adjusted variance. This is a separated\n",
    "        function as this factor is useful for both the design and analysis phase. \n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        num = self.num_var - 2*self.covar*self.num_mean/self.denom_mean + (self.num_mean**2)/(self.denom_mean**2)*self.denom_var\n",
    "        den = self.denom_mean**2\n",
    "        return num/den\n",
    "    \n",
    "    def calculate_sample_variance(self):\n",
    "        \"\"\"Full variance calculation requires sample size.\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return self.calculate_variance_factor() / self.sample_size\n",
    "    \n",
    "@dataclass\n",
    "class PowerParams:\n",
    "    \"\"\"Class to hold default inputs for power analysis. \n",
    "    As a note, MDE must be ABSOLUTE\n",
    "    \"\"\"\n",
    "    mde:float \n",
    "    alpha:float = 0.05\n",
    "    power:float = 0.8\n",
    "    n_variants:int=2\n",
    "\n",
    "    def calculate_z_params(self) -> tuple:\n",
    "        \"\"\"Return the equivalent z-score\n",
    "        of the alpha and power params.\n",
    "        It assumes a two-tails test by default.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        z_alpha = norm.ppf(1-self.alpha/2)\n",
    "        z_beta = norm.ppf(self.power)\n",
    "        return (z_alpha, z_beta)\n",
    "    \n",
    "\n",
    "def aggregate_ratio_data(df:pd.DataFrame, denom_col:str, num_col:str) -> DeltaParameters:\n",
    "    \"\"\"Take a dataframe that holds information at the randomization level (e.g user) and \n",
    "    calculate the variance/averages parameters used in the delta method.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): _description_\n",
    "        session_col (str): _description_\n",
    "        conversion_col (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        DeltaParameters: _description_\n",
    "    \"\"\"\n",
    "    params =  {\n",
    "            \"denom_mean\": df[denom_col].mean()\n",
    "            , \"num_mean\": df[num_col].mean()\n",
    "            , \"denom_var\": df[denom_col].var()\n",
    "            , \"num_var\":df[num_col].var()\n",
    "            , \"covar\":df[denom_col].cov(df[num_col])\n",
    "            , \"cvr\": df[num_col].sum() / df[denom_col].sum()\n",
    "            , \"sample_size\": df.shape[0]\n",
    "        }\n",
    "    return DeltaParameters(**params)\n",
    "\n",
    "def calculate_delta_method_sample_size(delta_params: DeltaParameters, power_inputs:PowerParams) -> float:\n",
    "    \"\"\"Calculate number of users (sample size) using the delta method.\n",
    "    Method details are in this paper: https://arxiv.org/abs/2305.16459\n",
    "\n",
    "    As a summary, the delta method uses a corrected formula to get\n",
    "    the correct variance in the case sessions are correlated. This correlation usually happens\n",
    "    experiment randomizes on users but CVR is on session level.\n",
    "\n",
    "    Args:\n",
    "        delta_params (DeltaParameters): _description_\n",
    "        power_inputs (PowerInputs): _description_\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    h = delta_params.calculate_variance_factor()\n",
    "    z_alpha, z_power = power_inputs.calculate_z_params()\n",
    "    k = math.ceil ( ( 2 * h * ( (z_alpha + z_power)**2)) / (power_inputs.mde ** 2) )\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TestResult:\n",
    "    statistic:str\n",
    "    statistic_val:float\n",
    "    p_val:float \n",
    "    is_significant:bool \n",
    "    alpha:float\n",
    "\n",
    "\n",
    "def variant_name_generator(n_variants:int) -> list[str]:\n",
    "    \"\"\"Generate a list of variant names starting from \"Control\"\n",
    "    up to VariantX where X is the number of variants to use\n",
    "    in an Experiment\n",
    "\n",
    "    Args:\n",
    "        n_variants (int): Number of variants (including Control)\n",
    "\n",
    "    Returns:\n",
    "        list[str]: _description_\n",
    "    \"\"\"\n",
    "    return [\"Control\"] + [f\"Variation{x}\" for x in range(1, n_variants)]\n",
    "\n",
    "\n",
    "def allocate_into_variants(df:pd.DataFrame, n_variants:int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    Add a new column called \"test_variant\" in which rows are assigned to\n",
    "    one of the Variants\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): _description_\n",
    "        n_variants (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    variant_list = variant_name_generator(n_variants)\n",
    "    return (\n",
    "        df \n",
    "        .assign(\n",
    "            test_variant = np.random.choice(variant_list, df.shape[0])\n",
    "        )\n",
    "    )\n",
    "\n",
    "def split_into_a_b(df:pd.DataFrame, variant_a:str, variant_b:str):\n",
    "    \"\"\"Simply split a single dataframe into two variants. \n",
    "    As a future improvement, support split into a/b/n. \n",
    "    Args:\n",
    "        df (pd.DataFrame): _description_\n",
    "        variant_a (str): _description_\n",
    "        variant_b (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    df_var_a = df.query(\"test_variant==@variant_a\") \n",
    "    df_var_b = df.query(\"test_variant==@variant_b\")\n",
    "    return df_var_a, df_var_b\n",
    "\n",
    "\n",
    "def apply_delta_method_test(var_a:pd.DataFrame, var_b:pd.DataFrame, denom_col:str, num_col:str, alpha:float=0.05) -> bool:\n",
    "    \"\"\"This function applies hypothesis testing following the delta method for ratio metric.\n",
    "    In a nutshell, once the corrected variance has been calculated, estimate the z-score\n",
    "    and subsequent p-value.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        var_a (pd.DataFrame): _description_\n",
    "        var_b (pd.DataFrame): _description_\n",
    "        denom_col (str): _description_\n",
    "        num_col (str): _description_\n",
    "        alpha (float, optional): _description_. Defaults to 0.05.\n",
    "\n",
    "    Returns:\n",
    "        bool: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # aggregate input data\n",
    "    agg_var_a = var_a.pipe(aggregate_ratio_data, denom_col, num_col)\n",
    "    agg_var_b = var_b.pipe(aggregate_ratio_data, denom_col, num_col)\n",
    "\n",
    "    # simulate h0\n",
    "    cvr_diff = agg_var_b.cvr - agg_var_a.cvr\n",
    "    var_sum = agg_var_b.calculate_sample_variance() + agg_var_a.calculate_sample_variance()\n",
    "\n",
    "    # calculate p-value\n",
    "    z_score = cvr_diff / np.sqrt(var_sum)\n",
    "    p_val = min(norm.cdf(z_score), 1-norm.cdf(z_score))\n",
    "    is_significant = p_val < alpha / 2\n",
    "\n",
    "    return TestResult(\n",
    "        statistic=\"z-test\",\n",
    "        statistic_val=z_score,\n",
    "        p_val=p_val, \n",
    "        is_significant = is_significant,\n",
    "        alpha = alpha / 2\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula Sample size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3654"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_params = PowerParams(mde=0.01, n_variants=2)\n",
    "delta_params = aggregate_ratio_data(test_area, \"n_sessions\", \"n_conversions\")\n",
    "size_per_variant = calculate_delta_method_sample_size(delta_params, power_params)\n",
    "size_per_variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "Weight is used to easily modify the sample size to take from the dataframe. This is if i want to take lower or higher sample sizes than what the formula says to check if simulation validates the sample size output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>area_name</th>\n",
       "      <th>perseus_client_id</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>n_conversions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>812826</th>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Kadıköy</td>\n",
       "      <td>1699548984594.761799240117872985.ZSoHiIJlQR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338236</th>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Kadıköy</td>\n",
       "      <td>1661190068086.921797088482393544.C5eok0SEMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446559</th>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Kadıköy</td>\n",
       "      <td>1677414917789.0840827516.tnowdnsboe</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285857</th>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Kadıköy</td>\n",
       "      <td>1671464980063.4701156324.nnixhfsiou</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871687</th>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Kadıköy</td>\n",
       "      <td>1676534004157.5129371850.hioemrjlpj</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city area_name                            perseus_client_id  \\\n",
       "812826   Istanbul   Kadıköy  1699548984594.761799240117872985.ZSoHiIJlQR   \n",
       "1338236  Istanbul   Kadıköy  1661190068086.921797088482393544.C5eok0SEMH   \n",
       "2446559  Istanbul   Kadıköy          1677414917789.0840827516.tnowdnsboe   \n",
       "285857   Istanbul   Kadıköy          1671464980063.4701156324.nnixhfsiou   \n",
       "1871687  Istanbul   Kadıköy          1676534004157.5129371850.hioemrjlpj   \n",
       "\n",
       "         n_sessions  n_conversions  \n",
       "812826            1              0  \n",
       "1338236           1              0  \n",
       "2446559           9              0  \n",
       "285857            1              0  \n",
       "1871687           9              1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 1.5\n",
    "\n",
    "sample_df = test_area.sample(\n",
    "    n = int(weight*size_per_variant*power_params.n_variants)\n",
    "    , replace= False\n",
    ")\n",
    "\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 57.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results_AA = []\n",
    "for it in tqdm(range(1000)):\n",
    "\n",
    "    it_df = sample_df.sample(frac=1, replace=True)\n",
    "\n",
    "    control, variation = (\n",
    "        it_df\n",
    "        .pipe(allocate_into_variants, 2)\n",
    "        .pipe(split_into_a_b, \"Control\", \"Variation1\")\n",
    "    )\n",
    "\n",
    "    significant = apply_delta_method_test(\n",
    "        var_a = control\n",
    "        , var_b = variation\n",
    "        , denom_col=\"n_sessions\"\n",
    "        , num_col=\"n_conversions\"\n",
    "        , alpha=power_params.alpha\n",
    "\n",
    "    )\n",
    "\n",
    "    results_AA.append(significant)\n",
    "\n",
    "# np.mean(results_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B\n",
    "\n",
    "Difficulty here is how to correctly apply the treatment as a noise. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_noise(variation:pd.DataFrame, mde:float, denom_col:str, num_col:str) -> pd.DataFrame:\n",
    "    \"\"\"Simulate the treatment effect. The key is to model the target metric\n",
    "    distribution. This method is based on the BinomialNoiser class\n",
    "    from: https://github.com/deliveryhero/logistics-ds-location-researches/blob/main/choice_ab_test_analysis/src/basic_noisers.py\n",
    "\n",
    "    The logic is to view use the number of session as variable to cohort the users. Users who over a period\n",
    "    of time has done the same number of session, their conversion behaviour should also be similar, on average.\n",
    "    The treatment effect is added to this cohort behaviour.\n",
    "\n",
    "    another option, not implemented here, is to fit a distribution of the CVR by user and draw a sample\n",
    "    for each user. This is what they did in the reference paper https://arxiv.org/abs/2305.16459. The reason I\n",
    "    didn't implement it here is that I have a highly skew distribution with many user with 0 CVR which requires more research into which\n",
    "    distribution I can use. In the paper they use a normal for the simulation which is not applicable to this context.\n",
    "    \n",
    "    Args:\n",
    "        variation (pd.DataFrame): _description_\n",
    "        mde (float): _description_\n",
    "        denom_col (str): _description_\n",
    "        num_col (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    bucket_df = (\n",
    "        variation\n",
    "        .assign(\n",
    "            bucket_cvr = variation[num_col] / variation[denom_col]\n",
    "        )    .groupby(denom_col, as_index=False)\n",
    "        [\"bucket_cvr\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "\n",
    "    return (\n",
    "        variation\n",
    "        .drop(columns=[num_col])\n",
    "        .merge(bucket_df, left_on=[denom_col], right_on=[denom_col])\n",
    "        .assign(**{\n",
    "            num_col: lambda df: np.random.binomial(\n",
    "                n=df[denom_col] \n",
    "            , p=(df[\"bucket_cvr\"] + mde).clip(0,1) \n",
    "            )}\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:22<00:00, 44.75it/s]\n"
     ]
    }
   ],
   "source": [
    "results_AB = []\n",
    "for it in tqdm(range(1000)):\n",
    "\n",
    "    it_df = sample_df.sample(frac=1, replace=True)\n",
    "\n",
    "    control, variation = (\n",
    "        it_df\n",
    "        .pipe(allocate_into_variants, 2)\n",
    "        .pipe(split_into_a_b, \"Control\", \"Variation1\")\n",
    "    )\n",
    "\n",
    "    variation_adj = add_noise(variation, power_params.mde, \"n_sessions\", \"n_conversions\")\n",
    "\n",
    "    significant = apply_delta_method_test(\n",
    "        var_a = control\n",
    "        , var_b = variation_adj\n",
    "        , denom_col=\"n_sessions\"\n",
    "        , num_col=\"n_conversions\"\n",
    "        , alpha=power_params.alpha\n",
    "\n",
    "    )\n",
    "\n",
    "    results_AB.append(significant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.048, 0.935)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([x.is_significant for x in results_AA]), np.mean([x.is_significant for x in results_AB])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
