# Pricing Performance Holdouts Pipeline

This repository contains the full data extraction, cleaning, CUPED adjustment, and storage pipeline for pricing holdout experiments across food delivery platforms.

The pipeline supports Google BigQuery data extraction, pandas data processing, bootstrapping, Welchâ€™s t-tests, and local or GCS parquet storage.

---

## ğŸ“‚ Project Structure

pricing_performance_holdouts/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ bigquery_queries.py # SQL query generators
â”‚ â”œâ”€â”€ extract.py # BigQuery client + data extraction
â”‚ â”œâ”€â”€ transform.py # data cleaning + filtering
â”‚ â”œâ”€â”€ cuped.py # CUPED variance reduction methods
â”‚ â””â”€â”€ store.py # upload to GCS or save locally
â”‚
â”œâ”€â”€ analysis/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ bootstrap.py # bootstrap confidence intervals
â”‚ â”œâ”€â”€ ttest.py # Welch's t-test + plotting
â”‚ â””â”€â”€ plotting.py # plotting utilities
â”‚
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ dates.py # ISO week utilities
â”‚ â””â”€â”€ logging_config.py # centralized logging setup
â”‚
â”œâ”€â”€ tests/ # unit tests
â”‚
â”œâ”€â”€ outputs/ # local parquet files
â”‚
â”œâ”€â”€ pipelines/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ historical_pipeline.py # Weekly cummulative historical data extraction pipeline
â”‚ â””â”€â”€ run_pipeline.py # CLI entrypoint to run pipeline
â”‚
â”œâ”€â”€ config.yaml # config file (project_id, bucket, paths etc.)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ’» Setup

1ï¸âƒ£ Clone the repository:
```bash
git clone https://github.com/your-org/pricing_performance_holdouts.git
cd pricing_performance_holdouts

2ï¸âƒ£ Create a virtual environment:
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies:
pip install -r requirements.txt

âš™ï¸ Configuration
Edit config.yaml to set:
    your GCP project
    BigQuery dataset/table names
    local output paths
    GCS bucket names (optional)

Example config.yaml:
project_id: "your-gcp-project-id"
gcs_bucket: "holdout_data"
local_output_dir: "./outputs"

You can run the full backfill pipeline directly from command line:
cd pricing_performance_holdouts
python -m pipelines.run_pipeline

Alternatively inside a Python script or notebook:

from pipelines.historical_pipeline import store_data_historically

store_data_historically(
    project_id="your-gcp-project-id",
    entities=["entity_1", "entity_2"],
    year=2025,
    restaurant_flag="IN",
    save_local=True
)

ğŸ‘¥ Contributors
Your Shazeb Asad (@shazebasad-dh)



