{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operators import *\n",
    "from queries import *\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.lafaurie/opt/anaconda3/envs/eda_env/lib/python3.10/site-packages/google/auth/_default.py:83: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# init operator\n",
    "hs_transfer_operator = HSTransferOperator(\n",
    "    project_id = \"logistics-data-staging-flat\"\n",
    "    , credentials = \"/Users/s.lafaurie/.config/gcloud/application_default_credentials.json\"\n",
    "    , dest_project_id = \"dh-logistics-product-ops\"\n",
    "    , dataset_id = \"pricing\"\n",
    "    , env=\"LOCAL\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCREMENTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating staging task...\n",
      "Job ID 6f028a86-6e44-4a35-900e-3201085cb7ab successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from BigQuery into Polars successful\n",
      "\n",
      "        Loaded 273642 rows \n",
      "        to BigQuery table hs_sa_rdf_orders_stg \n",
      "        in dh-logistics-product-ops:pricing\n",
      "        \n",
      "Initiating merging task...\n",
      "Merge has finished\n"
     ]
    }
   ],
   "source": [
    "# create staging data\n",
    "hs_transfer_operator.run_dag(\n",
    "            staging_query = STAGING_QUERY\n",
    "        , merge_query = MERGE_QUERY\n",
    "        , staging_table_name = \"hs_sa_rdf_orders_stg\"\n",
    "        , production_table_name = \"hs_sa_rdf_orders\"\n",
    "        , end_date = datetime.today()\n",
    "        , days_back = 2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKFILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.today()\n",
    "start_date = datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_chunks_from_period(start_date, end_date, chunk_size=14):\n",
    "    period_chunks = []\n",
    "    date_i = start_date\n",
    "    while date_i <= end_date:\n",
    "        start_i = date_i\n",
    "        end_i =  start_i + timedelta(days=chunk_size)\n",
    "        period_chunks.append((start_i, min(end_i, end_date)))\n",
    "        date_i = end_i \n",
    "    return period_chunks\n",
    "\n",
    "\n",
    "date_chunks = get_chunks_from_period(start_date, end_date, 30)  \n",
    "end_date_chunks  = [x[1] for x in date_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for 2022-05-31\n",
      "Initiating staging task...\n",
      "Job ID de4e6726-413f-4ecb-8414-dbc78e2aca6d successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Query is running:   0%|\u001b[32m          \u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 3822344 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2022-06-30\n",
      "Initiating staging task...\n",
      "Job ID 3e0cd895-552e-4a3e-b510-2d8831035fe3 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 5052404 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2022-07-30\n",
      "Initiating staging task...\n",
      "Job ID 01e2e1bb-ad3f-4098-8779-f3e959811670 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 4462465 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2022-08-29\n",
      "Initiating staging task...\n",
      "Job ID 3b8e5d5c-c19d-459c-8865-7a3cf8b86a0a successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 4712944 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2022-09-28\n",
      "Initiating staging task...\n",
      "Job ID e72136f3-84a7-48cb-965c-0b707b32147b successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 5111729 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2022-10-28\n",
      "Initiating staging task...\n",
      "Job ID 00b8f74f-566c-4bc9-bf09-45f916194c02 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 5118810 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2022-11-27\n",
      "Initiating staging task...\n",
      "Job ID 9cea2839-11a4-475f-8890-aab0b10f96fc successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 5355132 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2022-12-27\n",
      "Initiating staging task...\n",
      "Job ID df679173-92cb-488e-8522-70979a60b256 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 6117155 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2023-01-26\n",
      "Initiating staging task...\n",
      "Job ID 1720d574-8502-480c-b47f-1d8d5229300b successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 5041937 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2023-02-25\n",
      "Initiating staging task...\n",
      "Job ID d6e9ea3b-be2e-48ba-8e6f-56983298ab05 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 5617817 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2023-03-27\n",
      "Initiating staging task...\n",
      "Job ID c4a6210d-2986-45a7-9d24-2f7722e681b9 successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 4948786 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n",
      "Running pipeline for 2023-04-04\n",
      "Initiating staging task...\n",
      "Job ID 8d47f28e-90ce-4fc7-922d-4159da48f11a successfully executed: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Loading from bigQuery into Polars succesful\n",
      "Loaded 4399182 rows to BigQuery table hs_sa_rdf_orders_stg in dh-logistics-product-ops:pricing\n",
      "\n",
      "Initiating merging task...\n",
      "Merge has finished\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for end_date_i in end_date_chunks:\n",
    "    print(f\"Running pipeline for {end_date_i.strftime('%Y-%m-%d')}\")\n",
    "    # create staging data\n",
    "    hs_transfer_operator.run_dag(\n",
    "                staging_query = STAGING_QUERY\n",
    "            , merge_query = MERGE_QUERY\n",
    "            , staging_table_name = \"hs_sa_rdf_orders_stg\"\n",
    "            , production_table_name = \"hs_sa_rdf_orders\"\n",
    "            , end_date = end_date_i\n",
    "            , days_back = 30\n",
    "    )\n",
    "    print(f\"Done\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
