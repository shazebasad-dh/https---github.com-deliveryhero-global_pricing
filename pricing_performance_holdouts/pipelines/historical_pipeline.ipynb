{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.extract import initialize_bigquery_client, extract_data\n",
    "from data.bigquery_queries import get_marketing_data, get_dps_data\n",
    "from data.transform import apply_cleanup\n",
    "from data.cuped import apply_cuped_adjustment\n",
    "from data.store import store_data_cloud\n",
    "from utils.dates import get_iso_week_mondays\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import logging\n",
    "from data.extract import initialize_bigquery_client, extract_data\n",
    "from data.bigquery_queries import get_marketing_data, get_dps_data\n",
    "from data.transform import apply_cleanup\n",
    "from data.cuped import apply_cuped_adjustment\n",
    "from data.store import store_data_cloud\n",
    "from utils.dates import get_iso_week_mondays\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def store_data_historically(project_id: str,\n",
    "                            entities: list,\n",
    "                            year: int = 2025,\n",
    "                            min_date: date = None,\n",
    "                            max_date: date = None,\n",
    "                            restaurant_flag: str = 'IN',\n",
    "                            pre_post_metric_pairs: list = [(\"orders_pre\", \"orders_post\"),\n",
    "                                                           (\"analytical_profit_pre\", \"analytical_profit_post\")],\n",
    "                            save_local: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Backfill pipeline to extract, clean, CUPED adjust and store weekly data.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): GCP project ID.\n",
    "        entities (list): Entity IDs to filter.\n",
    "        year (int): Year to get all ISO weeks for.\n",
    "        min_date (date, optional): Earliest date to include (Monday). Defaults to None.\n",
    "        max_date (date, optional): Latest date to include (Monday). Defaults to latest Monday.\n",
    "        restaurant_flag (str): 'IN' or 'NOT IN' for restaurant filtering.\n",
    "        pre_post_metric_pairs (list): List of (pre, post) metric pairs for CUPED.\n",
    "        save_local (bool): If True, save local parquet files. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    client = initialize_bigquery_client(project_id)\n",
    "\n",
    "    # If max_date is None, set to latest Monday\n",
    "    if max_date is None:\n",
    "        today = date.today()\n",
    "        max_date = today - timedelta(days=today.weekday())\n",
    "\n",
    "    week_mondays = get_iso_week_mondays(year, min_date=min_date, max_date=max_date)\n",
    "    logger.info(f\"Starting historical storage for {year} with {len(week_mondays)} weeks.\")\n",
    "\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    for week in week_mondays:\n",
    "        \n",
    "        logger.info(f\"Processing week: {week}\")\n",
    "\n",
    "        mkt_query = get_marketing_data(entities, week, restaurant_flag=restaurant_flag)\n",
    "        dps_query = get_dps_data(entities, week, restaurant_flag=restaurant_flag)\n",
    "\n",
    "        df_raw = extract_data(client, mkt_query, dps_query)\n",
    "        df_raw[\"as_of_date\"] = week\n",
    "\n",
    "        df_clean = apply_cleanup(df_raw)\n",
    "        \n",
    "        all_data = pd.concat([all_data, df_clean], ignore_index=True)\n",
    "\n",
    "    df_cuped = apply_cuped_adjustment(all_data, pre_post_metric_pairs=pre_post_metric_pairs)\n",
    "\n",
    "    store_data_cloud(\n",
    "        df=df_cuped,\n",
    "        week_dates=week_mondays,\n",
    "        save_cloud_storage=False,\n",
    "        save_local=save_local\n",
    "    )\n",
    "\n",
    "    logger.info(\"Historical storage complete.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
